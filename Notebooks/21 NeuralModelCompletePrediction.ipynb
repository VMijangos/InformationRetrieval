{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e33fdd6e",
   "metadata": {},
   "source": [
    "# Aprendizaje de embeddings supervisados\n",
    "\n",
    "En las redes neuronales, los embeddings o representaciones vectoriales abstractas, son parte del aprendizaje de la red. Aquí presentamos una implementación de una red neuronal que estima los valores de relevancia entre un término y un documento, pero que además aprende las representaciones vectoriales de éstos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6a3e1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import brown\n",
    "from nltk.stem import SnowballStemmer\n",
    "from collections import defaultdict, Counter\n",
    "from itertools import chain\n",
    "from operator import itemgetter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24476414",
   "metadata": {},
   "source": [
    "### Preparación de los datos\n",
    "\n",
    "Utilizamos el corpus Brown y pre-procesamos los datos aplicando una stopword, stemmer y pasando todo a minúsculas, así como eliminando caracteres no relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a39edd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['cp01', 'cp02', 'cp03', 'cp04', 'cp05', 'cd01', 'cd02', 'cd03', 'cd04', 'cd05'])\n"
     ]
    }
   ],
   "source": [
    "#Stopwords\n",
    "paro = stopwords.words('english')\n",
    "#Documentos de los tópicos considerados\n",
    "ids = brown.fileids(categories=['romance'])[:5] + brown.fileids(categories=['religion'])[:5]\n",
    "#Stemmer\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "#Guarda las palabras\n",
    "BagOfWords = defaultdict(list)\n",
    "for i in ids:\n",
    "    #Genera las palabras de cada documento\n",
    "    words = brown.words(i)\n",
    "    for w in words:\n",
    "        #Aplica stopwords\n",
    "        if w in paro or w.isalpha() == False:\n",
    "            pass\n",
    "        else:\n",
    "            #Aplica stemmer y guarda\n",
    "            BagOfWords[i].append(stemmer.stem(w))\n",
    "\n",
    "print(BagOfWords.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c484d18e",
   "metadata": {},
   "source": [
    "Ahora creamos el conjunto de entrenamiento, el cual será un conjunto supervisado. Cada ejemplo de entrenamiento se conformará de tres elementos:\n",
    "\n",
    "$$(d_i, t_j, y_{i,j})$$\n",
    "\n",
    "$d_i$ (el documento) y $t_j$ (el término) serán la entrada de la red, mientras que $y_{i,j}$ será la salida de la red que es un valor de relevancia; en este caso tomamos como valor de relevancia la frecuencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ea99452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0, 4), (0, 1, 2), (0, 2, 4), (0, 3, 1), (0, 4, 16), (0, 5, 15), (0, 6, 3), (0, 7, 9), (0, 8, 2), (0, 9, 1)]\n"
     ]
    }
   ],
   "source": [
    "#Frecuencia de términos\n",
    "freqs = Counter(list(chain(*BagOfWords.values())))\n",
    "#Índices para términos\n",
    "terms = {w:k for k,w in enumerate(freqs.keys())}\n",
    "#Índices para documentos\n",
    "docs = {d:l for l,d in enumerate(BagOfWords.keys())}\n",
    "\n",
    "#Crea el dataset de entrenamiento\n",
    "train_set = []\n",
    "for d, t_list in BagOfWords.items():\n",
    "    doc_frec = Counter(t_list)\n",
    "    for t, t_frec in doc_frec.items():\n",
    "        train_set.append((docs[d], terms[t], t_frec))\n",
    "        \n",
    "print(train_set[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d4c54c",
   "metadata": {},
   "source": [
    "### Generación de la red\n",
    "\n",
    "Nuestra red tomará dos entradas, el documento $d_i$ y el término $t_j$, cada uno de estos elementos pasará por una capa de embedding. De tal forma que tendremos un vector representado al documento y otro representado al término. Estos vectores se concatenan y pasan por capas densas hasta obtener una salida que será la predicción de la relevancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbc5ebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5803476f",
   "metadata": {},
   "source": [
    "Utilizamos pytorch para definir la red como una clase RIModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c0acf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Número de documentos\n",
    "n_docs = len(docs)\n",
    "#Número de términos\n",
    "n_terms = len(terms)\n",
    "\n",
    "class RIModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Clase para definir la arquitectura de la red.\n",
    "    \"\"\"\n",
    "    def __init__(self, emb_dims=128, h_dim=256):\n",
    "        super().__init__()\n",
    "        #dimensión de embeddings\n",
    "        self.emb_dims = emb_dims\n",
    "        #Embedding para documento\n",
    "        self.emb_docs = nn.Embedding(n_docs, emb_dims)\n",
    "        #Embedding para término\n",
    "        self.emb_terms = nn.Embedding(n_terms, emb_dims)\n",
    "        #Capas densas\n",
    "        self.ffw = nn.Sequential(nn.Linear(2*emb_dims, 2*h_dim), nn.Tanh(),\n",
    "                                 nn.Linear(2*h_dim, h_dim), nn.Tanh(),\n",
    "                                 nn.Linear(h_dim, 1))\n",
    "        \n",
    "    def forward(self,x_doc, x_term):\n",
    "        #Cálculo y concatenación de embeddings\n",
    "        embs_concat = torch.cat((self.emb_docs(x_doc), self.emb_terms(x_term)), axis=1)\n",
    "        #Aplicación de las capas densas\n",
    "        out = self.ffw(embs_concat)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffef201",
   "metadata": {},
   "source": [
    "Ahora entrenamos la red con los datos de entrenamiento que hemos obtenido. Dado que queremos predecir valores reales, usamos el riesgo del error cuadrático. Usamos un optimizador Adam con rango de aprendizaje de 0.1 y corremos por 25 épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8328ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [03:05<00:00,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 5s, sys: 106 ms, total: 3min 5s\n",
      "Wall time: 3min 6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Definimos la red\n",
    "net = RIModel(emb_dims=128, h_dim=256)\n",
    "#Función de riesgo\n",
    "risk = nn.MSELoss()\n",
    "#Otpimizador\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.1)\n",
    "#Número de épocas\n",
    "epochs = 25\n",
    "for t in tqdm(range(epochs)):\n",
    "    for d, t, s in train_set:\n",
    "        #Creamos índices de documento y término en torch\n",
    "        x_doc, x_term = torch.tensor([d]), torch.tensor([t])\n",
    "        #Aplicamos la red\n",
    "        pred = net(x_doc, x_term)\n",
    "        #Damos formato a las salidas\n",
    "        y = torch.tensor(s).reshape(1,1)\n",
    "        y = y.to(torch.float32)\n",
    "        #Calculamos el riesto\n",
    "        loss = risk(pred, y)\n",
    "        #Optimizamos\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4a7c88",
   "metadata": {},
   "source": [
    "### Sistema de consulta \n",
    "\n",
    "A partir de la red podemos obtener el sistema de consulta. Podemos aplicar la red de manera directa para obtener los valores de relevancia que esta predice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9deb9f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "def consult(term):\n",
    "    #Índice del término\n",
    "    x_term = torch.tensor([terms[term]])\n",
    "    for doc in docs.keys():\n",
    "        #Índice para documentos en colección\n",
    "        x_doc = torch.tensor([docs[doc]])\n",
    "        \n",
    "        #Devuelve la red entre término y documento\n",
    "        yield ( doc, brown.categories(doc)[0], float(net(x_doc,x_term).detach()[0][0]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e147d780",
   "metadata": {},
   "source": [
    "Podemos visualizar entonces el tipo de resultados que da en orden de relevancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc712397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cp05', 'romance', 0.9988749027252197)\n",
      "('cd02', 'religion', 0.9988749027252197)\n",
      "('cd05', 'religion', 0.9988749027252197)\n",
      "('cp01', 'romance', 0.9741750955581665)\n",
      "('cp02', 'romance', 0.9741750955581665)\n",
      "('cp03', 'romance', 0.9741750955581665)\n",
      "('cp04', 'romance', 0.9741750955581665)\n",
      "('cd01', 'religion', 0.9741750955581665)\n",
      "('cd03', 'religion', 0.9741750955581665)\n",
      "('cd04', 'religion', 0.9741750955581665)\n"
     ]
    }
   ],
   "source": [
    "result = consult('love')\n",
    "\n",
    "for r in sorted(result, key=itemgetter(2), reverse=True):\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2e57d9",
   "metadata": {},
   "source": [
    "### Uso de los embeddings\n",
    "\n",
    "Además de entrenar la red para predecir la relevancia, hemos generado embeddings para términos y documentos. Estos embeddings en tanto representaciones vectoriales se pueden utilizar para hacer consultas como si se tratara de un modelo de espacio vectorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64c449cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtención de los embeddings a partir de la red\n",
    "doc_embs = net.emb_docs.weight.detach().numpy()\n",
    "term_embs = net.emb_terms.weight.detach().numpy()\n",
    "\n",
    "def consult_embs(term):\n",
    "    \"\"\"\n",
    "    Función de consulta a partir de embeddings.\n",
    "    \"\"\"\n",
    "    #embedding de término\n",
    "    t_vec = term_embs[terms[term]]\n",
    "    \n",
    "    for doc in docs.keys():\n",
    "        #embeddings de documentos\n",
    "        d_vec = doc_embs[docs[doc]]\n",
    "        #Similitud coseno\n",
    "        s = np.abs(np.dot(t_vec, d_vec))/( np.linalg.norm(t_vec)*np.linalg.norm(d_vec) ) \n",
    "        \n",
    "        yield (doc, brown.categories(doc)[0], s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e010d6a2",
   "metadata": {},
   "source": [
    "Los resultados que se obtienen con estas consultas son los siguientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22380828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cd05', 'religion', 0.9335665)\n",
      "('cp05', 'romance', 0.9017998)\n",
      "('cd02', 'religion', 0.90087825)\n",
      "('cd04', 'religion', 0.8960338)\n",
      "('cd01', 'religion', 0.8324496)\n",
      "('cp01', 'romance', 0.7515694)\n",
      "('cp03', 'romance', 0.6937143)\n",
      "('cd03', 'religion', 0.67838824)\n",
      "('cp04', 'romance', 0.52966213)\n",
      "('cp02', 'romance', 0.18644014)\n"
     ]
    }
   ],
   "source": [
    "result = consult_embs('god')\n",
    "\n",
    "for r in sorted(result, key=itemgetter(2), reverse=True):\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f53a065",
   "metadata": {},
   "source": [
    "Finalmente, podemos visualizar el cómo se comportan los embeddings en el espacio vectorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e247ca16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Reducción de dimensionalidad\n",
    "X = np.concatenate((doc_embs, term_embs))\n",
    "red = PCA(n_components=2)\n",
    "X_red = red.fit_transform(X)\n",
    "\n",
    "#Función para visualizar los embeddings\n",
    "#Usa reducción de la dimensionalidad por PCA\n",
    "def plot(Z,ids, color='blue'):\n",
    "    r=0\n",
    "    plt.scatter(Z[:,0],Z[:,1], marker='o', c=color)\n",
    "    for label,x,y in zip(ids, Z[:,0], Z[:,1]):\n",
    "        plt.annotate(label, xy=(x,y), xytext=(-1,1), textcoords='offset points', ha='center', va='bottom')\n",
    "        r+=1\n",
    " \n",
    "#Visualización de embeddings\n",
    "plot(X_red[:10], docs.keys())\n",
    "plot(X_red[10:][[terms['god'], terms['spirit']]], ['god','love'], color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53090188",
   "metadata": {},
   "source": [
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
